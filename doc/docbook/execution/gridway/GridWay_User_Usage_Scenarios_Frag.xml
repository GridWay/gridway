<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd"
[

<!ENTITY % myents SYSTEM "../../entities">

%myents;

]>
<section>
  <section>
	<title>Single jobs: Submitting and monitoring the simplest job</title>

  <para>
    GWD should be configured and running. Check the <emphasis>Installation and
    Configuration Guide</emphasis> and <xref linkend='gridway-user-env-vars'/> to do
    that. Do not forget to create a proxy with
    <command>grid-proxy-init</command>
  </para>

  <para>
  To submit a job, you will need a Job Template. The most simple Job Template
  in GridWay could be:
  <screen>
EXECUTABLE=/bin/ls</screen>
  </para>
  <para>
  Save it as file <filename>jt</filename> in directory
  <filename>example</filename>.
  </para>

  <para>
  Use the <command>gwsubmit</command> command to submit the job:
  <screen>
$ gwsubmit -t example/jt</screen>
	</para>

  <para>
  Let see how many resources are available in our Grid, with
  <command>gwhost</command>:
  </para>

  <screen width='80'>
HID PRIO OS              ARCH   MHZ %CPU MEM(F/T)     DISK(F/T)  N(U/F/T) LRMS  HOSTNAME
0   1    Linux2.6.17-2-6 x86   3215  100 923/2027 105003/118812     0/1/2 Fork  cygnus.dacya.ucm.es
1   1    Linux2.6.17-2-6 x86   3216  189 384/2027 105129/118812     0/2/2 Fork  draco.dacya.ucm.es
2   1    Linux2.6.18-3-a x86_6 2211  100 749/1003   76616/77844     0/2/2 SGE   aquila.dacya.ucm.es
3   1                             0    0      0/0           0/0     0/0/0       hydrus.dacya.ucm.es
4   1    Linux2.6.18-3-a x86_6 2009   74  319/878 120173/160796     0/1/1 Fork  orion.dacya.ucm.es
5   1    Linux2.6.16.13- x86   3200  100  224/256       114/312     0/6/6 SGE   ursa.dacya.ucm.es</screen>

  <para>
  Note that hydrus is down in this example, so no information is received at all
  and of course, this host won't be considered in future scheduling decisions.
  If you want to retrieve more information about a single resource, issue the
  <command>gwhost</command> command followed by the host identification (HID):
  </para>

<screen width='80'>
$ gwhost 0
HID PRIO OS              ARCH   MHZ %CPU MEM(F/T)     DISK(F/T)  N(U/F/T) LRMS  HOSTNAME
5   1    Linux2.6.16.13- x86   3200  100  224/256       114/312     0/6/6 SGE   ursa.dacya.ucm.es

QUEUENAME            SL(F/T) WALLT CPUT  COUNT MAXR  MAXQ  STATUS   DISPATCH   PRIORITY
all.q                6/6     0     0     0     6     0     enabled  NULL       0</screen>

  <para>
  You can also check the resources that match your requirements with <command>gwhost -m 0</command>.
  </para>

  <screen>
HID QNAME      RANK  PRIO  SLOTS HOSTNAME
0   default    0     1     2     cygnus.dacya.ucm.es
1   default    0     1     0     draco.dacya.ucm.es
2   all.q      0     1     2     aquila.dacya.ucm.es
4   default    0     1     1     orion.dacya.ucm.es
5   all.q      0     1     6     ursa.dacya.ucm.es</screen>

  <para>
  Now, you can check the evolution of the job with the <command>gwps</command>
  command.
  <screen width='80'>
USER         JID DM   EM   RWS START    END      EXEC    XFER    EXIT NAME  HOST
jlvazquez    0   pend ---- 000 10:42:09 --:--:-- 0:00:00 0:00:00 --   jt    --

USER         JID DM   EM   RWS START    END      EXEC    XFER    EXIT NAME  HOST
jlvazquez    0   prol ---- 000 10:42:09 --:--:-- 0:00:00 0:00:01 --   jt    cygnus.dacya.ucm.es/Fork

USER         JID DM   EM   RWS START    END      EXEC    XFER    EXIT NAME  HOST
jlvazquez    0   wrap ---- 000 10:42:09 --:--:-- 0:00:27 0:00:04 --   jt    cygnus.dacya.ucm.es/Fork

USER         JID DM   EM   RWS START    END      EXEC    XFER    EXIT NAME  HOST
jlvazquez    0   wrap pend 000 10:42:09 --:--:-- 0:00:27 0:00:04 --   jt    cygnus.dacya.ucm.es/Fork

USER         JID DM   EM   RWS START    END      EXEC    XFER    EXIT NAME  HOST
jlvazquez    0   wrap actv 000 10:42:09 --:--:-- 0:00:27 0:00:04 --   jt    cygnus.dacya.ucm.es/Fork

USER         JID DM   EM   RWS START    END      EXEC    XFER    EXIT NAME  HOST
jlvazquez    0   epil ---- 000 10:42:09 --:--:-- 0:00:31 0:00:05 --   jt    cygnus.dacya.ucm.es/Fork

USER         JID DM   EM   RWS START    END      EXEC    XFER    EXIT NAME  HOST
jlvazquez    0   done ---- 000 10:42:09 10:43:01 0:00:31 0:00:08 0    jt    cygnus.dacya.ucm.es/Fork</screen>
  </para>

  <para>
  At the beginning, the job is in <emphasis>pending</emphasis> state and not
  allocated to any resource. Then, the job is allocated to
  cygnus.dacya.ucm.es/Fork and begins the <emphasis>prolog</emphasis> stage.
  </para>

  <note>
  <para>
  You can use option <option>-c &lt;delay></option> to see a continuous
  output of the <command>gwps</command> command.
  </para>
  </note>

  <para>
  You can see the job history with the <command>gwhistory</command> command:
  <screen width='80'>
$ gwhistory 0
HID START    END      PROLOG  WRAPPER EPILOG  MIGR    REASON QUEUE    HOST
0   10:42:22 10:43:01 0:00:04 0:00:31 0:00:04 0:00:00 ----   default  cygnus.dacya.ucm.es/Fork</screen>
  </para>

  <para>
  Now it's time to retrieve the results. As you specified by default, the
  results of the execution of this job will be in the same folder, in a text
  file called sdtout_file.$JOB_ID.
  <screen>
$ ls -lt example/
total 8
-rw-r--r-- 1 jlvazquez staff  0 2007-02-20 10:42 stderr.0
-rw-r--r-- 1 jlvazquez staff 72 2007-02-20 10:42 stdout.0
-rw-r--r-- 1 jlvazquez staff 19 2007-02-20 10:33 jt
$ cat example/stdout.0
job.env
stderr.execution
stderr.wrapper
stdout.execution
stdout.wrapper</screen>
  </para>

  <para>
  Done! You have done your first execution with GridWay!
  </para>
  </section>

  <section>
	<title>Array jobs: Calculating the &pi; number</title>

    <section>
		<title>Defining the problem</title>

    <para>
    This is a well known exercise. For our purposes, we will calculate the
    integral of the following function:
      <informalfigure>
        <graphic align="center" fileref="user/pi1.jpg"/>
      </informalfigure>
    </para>

    <para>
    Being f(x) = 4/(1+x2). So, &pi; will be the integral of f(x) in the
    interval [0,1].
   	</para>

    <para>
    In order to calculate the whole integral, it's interesting to divide the
    function in several sections and compute them separately:
    <informalfigure>
      <graphic align="center" fileref="user/pi2.jpg"/>
      </informalfigure>
    </para>

    <para>
    As you can see, the more sections you make, the more exact &pi; will be:
    <informalfigure>
      <graphic align="center" fileref="user/pi3.jpg"/>
    </informalfigure>
    </para>

    <para>
    So, you have a Grid with some nodes, you have GridWay... Why don't use them
    to calculate the &pi; number by giving all the nodes a section to compute
    with only one command?
    </para>

    <note>
    <para>
    You will find all the files needed to perform this example in the
    <filename>$GW_LOCATION/examples/pi</filename> directory.
    </para>
    </note>
		</section>

		<section>
		<title>The coding part</title>

    <para>
    For this example, we have chosen the C Programming Language. Create a text
    file called <filename>pi.c</filename> and copy inside the following lines:
    </para>

    <programlisting>
#include &lt;stdio.h>
#include &lt;string.h>

int main (int argc, char** args)
{
  int task_id;
  int total_tasks;
  long long int n;
  long long int i;

  double l_sum, x, h;

  task_id = atoi(args[1]);
  total_tasks = atoi(args[2]);
  n = atoll(args[3]);

  fprintf(stderr, "task_id=%d total_tasks=%d n=%lld\n", task_id, total_tasks, n);

  h = 1.0/n;

  l_sum = 0.0;

  for (i = task_id; i &lt; n; i += total_tasks)
  {
    x = (i + 0.5)*h;
    l_sum += 4.0/(1.0 + x*x);
  }

  l_sum *= h;

  printf("%0.12g\n", l_sum);

  return 0;
}
  </programlisting>

    <para>
    Now it's time to compile it:
    <screen>$ gcc -O3 pi.c -o pi</screen>
    </para>

    <para>
    after this, you should have an executable called <command>pi</command>. This
    command receives three parameters:
    <itemizedlist>
      <listitem>
        <para>
          Task identifier: The identifier of the current task.
        </para>
      </listitem>
      <listitem>
        <para>
          Total tasks: The number of tasks the computation should be divided
          into.
        </para>
      </listitem>
      <listitem>
        <para>
          Number of intervals: The number of intervals over which the integral
          is being evaluated.
        </para>
      </listitem>
    </itemizedlist>
  </para>
  </section>

  <section>
	<title>Defining the job</title>

  <para>
  For making GridWay work with your program, you must create a Job Template. In
  this case, we will call it <filename>pi.jt</filename>. Copy the following
  lines inside:
  <screen>
EXECUTABLE  = pi
ARGUMENTS   = ${TASK_ID} ${TOTAL_TASKS} 100000
STDOUT_FILE = stdout_file.${TASK_ID}
STDERR_FILE = stderr_file.${TASK_ID}
RANK        = CPU_MHZ</screen>
  </para>
  </section>

  <section>
	<title>Submitting the jobs</title>

    <para>
    This time, we will submit an array of jobs. This is done by issuing the
    following command:
    <screen>
$ gwsubmit -v -t pi.jt -n 4
ARRAY ID: 0

TASK JOB
0    0
1    1
2    2
3    3</screen>
    </para>

    <para>
    In order to wait for the jobs to complete, you can use the
    <command>gwwait</command> command.
    </para>

    <para>
    The argument passed to <command>gwwait</command> is the array identifier
    given by <command>gwsubmit</command> when executed with the
    <option>-v</option> option. It could be also obtained through
    <command>gwps</command>
    </para>

    <para>
    This command will block and return when all jobs have been executed:
    <screen>
$ gwwait -v -A 0
0   : 0
1   : 0
2   : 0
3   : 0</screen>
     This command, when issued with option <option>-v</option> shows the exit
     codes for each job in the array (usually, 0 means success).
    </para>
    </section>

    <section>
		<title>Result post-processing</title>

    <para>
    The execution of these jobs has returned some output files with the result
    of each execution:
    <screen>
stdout_file.0
stdout_file.1
stdout_file.2
stdout_file.3</screen>
    </para>

    <para>
    Now, we will need something to sum the results inside each file. For this,
    you can use an <command>awk</command> script like the following:
<screen width='80'>
$ awk 'BEGIN {sum=0} {sum+=$1} END {printf "Pi is %0.12g\n", sum}' stdout_file.*
Pi is 3.1415926536</screen>
    </para>

    <para>
    Well, not much precision, right? You could try it again, but this time with
    a much higher number of intervals (e.g. 10,000,000,000). Would you increment
    also the number of tasks? Which would be the best compromise?
    </para>

    <para>
    Do you imagine how easy would be to implement these steps in a shell script
    in order to perform them unattendedly? Here you are the prove:
    <programlisting>
#!/bin/sh

AID=`gwsubmit -v -t pi.jt -n 4 | head -1 | awk '{print $3}'`

if [ $? -ne 0 ]
then
    echo "Submission failed!"
    exit 1
fi

gwwait -v -A $AID

if [ $? -eq 0 ]
then
    awk 'BEGIN {sum=0} {sum+=$1} END {printf "Pi is %0.12g\n", sum}' stdout_file.*
else
    echo "Some tasks failed!"
fi
    </programlisting>
    </para>
    </section>
  </section>

  <section>
  <title>MPI jobs: Calculating the &pi; number again</title>

  <para>
  When applications show fine-grain parallelism, with small computation to
  communication ratio, and thus need lower latencies, MPI (Message Passing
  Interface) jobs give a better choice.
  </para>

  <para>
  Following the &pi; example, we will now perform its computation using MPI in a
  single job. Notice that MPI jobs can also be part of an array or complex job.
  </para>

  <note>
  <para>
  You will find all the files needed to perform this example in the
  <filename>$GW_LOCATION/examples/mpi</filename> directory.
  </para>
  </note>

  <para>
  Create a text file called <filename>mpi.c</filename> and copy inside the
  following lines:
  </para>

  <programlisting>
#include "mpi.h"
#include &lt;stdio.h>
#include &lt;math.h>

int main( int argc, char *argv[])
{
    int done = 0, n, myid, numprocs, i;
    double PI25DT = 3.141592653589793238462643;
    double mypi, pi, h, sum, x;
    double startwtime = 0.0, endwtime;
    int  namelen;
    char processor_name[MPI_MAX_PROCESSOR_NAME];

    MPI_Init(&amp;argc,&amp;argv);
    MPI_Comm_size(MPI_COMM_WORLD,&amp;numprocs);
    MPI_Comm_rank(MPI_COMM_WORLD,&amp;myid);
    MPI_Get_processor_name(processor_name,&amp;namelen);

    printf("Process %d on %s\n", myid, processor_name);

    n = 100000000;

    startwtime = MPI_Wtime();

    h   = 1.0 / (double) n;
    sum = 0.0;
    for (i = myid + 1; i &lt;= n; i += numprocs)
    {
        x = h * ((double)i - 0.5);
        sum += 4.0 / (1.0 + x*x);
    }
    mypi = h * sum;

    MPI_Reduce(&amp;mypi, &amp;pi, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);

    if (myid == 0)
    {
        printf("pi is approximately %.16f, Error is %.16f\n",
               pi, fabs(pi - PI25DT));
        endwtime = MPI_Wtime();
        printf("wall clock time = %f\n", endwtime-startwtime);
    }

    MPI_Finalize();

    return 0;
}
  </programlisting>

  <note>
  <para>
  For more information about MPI, see http://www.mcs.anl.gov/mpi.
  </para>
  </note>

  <para>
  Notice that the above program already performs postprocessing in a single
  operand reduction operation MPI_Reduce which sums the partial results
  obtained by each processor.
  </para>

  <para>
  Now it's time to compile it. Notice that you will need a compiler with MPI
  support like <command>mpicc</command>:
  <screen>$ mpicc -O3 mpi.c -o mpi</screen>
  </para>

  <para>
  Now you must create a Job Template. In this case, we will call it
  <filename>mpi.jt</filename>:
  <screen>
EXECUTABLE   = mpi

STDOUT_FILE   = stdout.${JOB_ID}
STDERR_FILE   = stderr.${JOB_ID}

RANK          = CPU_MHZ

TYPE          = "mpi"
NP            = 2
</screen>
  </para>

  </section>

  <section>
  <title>Workflows</title>

  <para>
  The powerful commands provided by GridWay to submit, control and synchronize
  jobs allow us to programmatically define complex jobs or workflows, where some
  jobs need data generated by other jobs. GridWay allows job submission to be
  dependent on the completion of other jobs. This new functionality provides
  support for the execution of workflows.
  </para>

  <para>
  GridWay allows scientists and engineers to express their computational
  problems by using workflows. The capture of the job exit code allows users to
  define workflows, where each task depends on the output and exit code from the
  previous task. They may even involve branching, looping and spawning of
  subtasks, allowing the exploitation of the parallelism on the workflow of
  certain type of applications. The bash script flow control structures and the
  GridWay commands allow the development of workflows with the following
  functionality:
  <itemizedlist>

    <listitem>
    <para>
    Sequence, parallelism, branching and looping structures
    </para>
    </listitem>

    <listitem>
    <para>
    The workflow can be described in an abstract form without referring to
    specific resources for task execution
    </para>
    </listitem>

    <listitem>
    <para>
    Quality of service constraints and fault tolerance are defined at task level
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
  Job dependencies can be specified at submission by using the
  <command>-d</command> option of the <command>gwsubmit</command> command. A Job
  with dependencies will be submitted in the hold state, and once all the jobs
  on which it depends have successfully finished, it will be released. You can
  also release this job by hand with the <command>gwkill</command>.
  </para>

  <section>
  <title>A sample of DAG workflow</title>

  <para>
  A DAG-based workflow consists of a temporal relationship between tasks, where
  the input, output or execution of one ore more tasks depends on one or more
  other tasks. For this example we have chosen a simple workflow.
  </para>

  <figure>
    <title>Workflow example.</title>
    <graphic align="center" fileref="user/gw_workflow.jpg"/>
  </figure>

  <para>
  In this example, job A generates a random number, jobs B and C add 1 to that
  number and, finally job D adds the result of these jobs. This is the final
  result is two times the number generated by A, plus two. In our case, the
  numbers are passed  between jobs using the standard output files.
  </para>

  <para>
  Job Template for job A (<filename>A.jt</filename>):
    <screen>
EXECUTABLE=/bin/echo
ARGUMENTS="$RANDOM"
STDOUT_FILE=out.A</screen>
  </para>

  <para>
  Job Template for jobs B and C (<filename>B.jt</filename> and
  <filename>C.jt</filename>):
  <screen>
EXECUTABLE=/usr/bin/expr
ARGUMENTS="`cat out.A`" + 1
INPUT_FILES=out.A
STDOUT_FILE=out.B #out.C for job C</screen>
  </para>

  <para>
  Job Template for job D (<filename>D.jt</filename>):
<screen>
EXECUTABLE=/usr/bin/expr
ARGUMENTS="`cat out.B`" + "`cat out.C`"
INPUT_FILES=out.B, out.C
STDOUT_FILE=out.workflow</screen>
  </para>

  <para>
  Once you have set up the previous Job Templates, the workflow can be easily
  submitted with the following commands:
  <screen>
$ gwsubmit -v -t A.jt
JOB ID: 5

$ gwsubmit -v -t B.jt -d "5"
JOB ID: 6

$ gwsubmit -v -t C.jt -d "5"
JOB ID: 7

$ gwsubmit -t C.jt -d "6 7"</screen>
  </para>

  <note>
  <para>
  In the previous example, jobs B and C can be submitted as an array
  job using just one template with output, <computeroutput>OUTPUT_FILES =
  out.${TASK_ID}</computeroutput>. Therefore, input of job D will be <computeroutput>
  INPUT_FILES = out.0, out.1</computeroutput>.
  </para>
  </note>

  <para>
  The above steps can be easily implemented in a shell script.
  <programlisting>
#!/bin/sh

A_ID=`gwsubmit -v -t A.jt | cut -f2 -d':' | cut -f2 -d' '`
B_ID=`gwsubmit -v -t B.jt -d "$A_ID" | cut -f2 -d':' | cut -f2 -d' '`
C_ID=`gwsubmit -v -t C.jt -d "$A_ID" | cut -f2 -d':' | cut -f2 -d' '`
D_ID=`gwsubmit -v -t D.jt -d "$B_ID $C_ID"| cut -f2 -d':' | cut -f2 -d' '`

#Sync with last job of the workflow
gwwait $D_ID

echo "Random number `cat out.A`"
echo "Workflow computation `cat out.workflow`"
  </programlisting>
  </para>

  <para>
  Note that when input and output files vary depending on the iteration or job
  id number, you should generate Job Templates dynamically before submitting
  each job. This can be done programmatically by using the DRMAA API, or via
  shell scripting.
  </para>

  <section>
	<title>Using gwdag tool</title>
	
	<para>
		Alternatively you can describe DAG workflows using a file similar to the one used by Condor DAGMAN. In this case the dependencies are not managed by GW but by the gwdag tool. You only have to substitute Condor job descriptions with GridWay job templates. Here is a file describing the same DAG as the previous example:
	</para>
	
	<screen>
JOB  A  A.jt
JOB  B  B.jt
JOB  C  C.jt
JOB  D  D.jt
PARENT A CHILD B C
PARENT B C CHILD D</screen>

	<para>
		To submit this job you only have to specify the file describing this DAG to gwdag tool:
	</para>
	
	<screen>
$ gwdag &lt;name of the file></screen>

	<para>
		You can also get a DOT file for a DAG description that you can use later to generate a graph showing the flow using -d flag:
	</para>
	
	<screen>
$ gwdag -d &lt;name of the file> > &lt;name of the dot file></screen>

<figure>
  <title>Dag graph generated by the gwdag tool.</title>
  <graphic align="center" fileref="user/gw_dag.png"/>
</figure>

	
  </section>

  </section>
  </section>
</section>
