<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook V4.1//EN">
<book lang="en">
    <bookinfo>
        <title>GridWay 5 Documentation: Installation and Configuration Guide</title>

        <pubdate>November, 2006</pubdate>
        <copyright>
            <year>2002-2006</year>
            <holder>GridWay Team, Distributed Systems Architecture
                Group, Universidad Complutense de Madrid.</holder>
        </copyright>
        <legalnotice>
            <para>
                Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at
            </para>
            <para>
                <ulink url="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</ulink>
            </para>
            <para>
                Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
            </para>
            <para>
                Any academic report, publication, or other academic disclosure of results obtained with this Software will acknowledge this Software's use by an appropriate citation.
            </para>
            <para>
              GridWay is an effort undergoing incubation at Globus. Incubation is
              required of all newly accepted projects until a further review indicates
              that the infrastructure, communications, and decision making process
              have stabilized in a manner consistent with other successful Globus
              projects. While incubation status is not necessarily a reflection of
              the completeness or stability of the code, it does indicate that the
              project has yet to be fully endorsed by Globus.
            </para>
        </legalnotice>
    </bookinfo>

<chapter>
<title>Grid Computing Key Concepts</title>

  <sect1>
  <title>What is a Grid Infrastructure?</title>
    <para>
    <emphasis>Several Distributed Resource Management Systems (DRMS) have been
    developed to provide workload management of applications.</emphasis> These
    systems first appeared in the late eighties, coinciding with the advent of
    parallel and distributed platforms, such as high performance computing
    servers and clusters. There are a number of commercial and open source
    local workload management systems available today, such as
    <ulink url="http://www.openpbs.org/">PBS</ulink>,
    <ulink url="http://www.sun.com/software/gridware/">SGE</ulink>,
    <ulink url="http://www.platform.com/">LSF</ulink> or
    <ulink url="http://www.cs.wisc.edu/condor/">Condor</ulink>, and each one is
    used for different underlying computer architectures and execution profiles.
    In any case their  benefits in cost minimization and performance
    maximization are mainly due to greater utilization of underlying resources.
    </para>

    <para>
    <emphasis>Even though DRM systems share many capabilities, mainly batch
    queuing, job scheduling and resource management; they do not provide a
    common interface and security framework, and so their integration is not
    possible.</emphasis> Such lack of interoperability involves the existence
    within an organization of independent computational platforms
    <emphasis>(vertical silos)</emphasis> responsible for distinct functions
    that require specialized administration skills and generates
    over-provisioning and global load unbalance. Moreover, such technologies
    are also unsuitable to build computational infrastructures where resources
    are scattered across several administrative domains, each with its own
    security policy and DRM system. A grid infrastructure offers a common layer
    to integrate these non-interoperable computational platforms by defining a
    consistent set of abstraction and interfaces for access to, and management
    of, shared resources
    (<ulink url="http://www.ggf.org/documents/Diff_Faces_foster.pdf">Ian Foster
    and Steven Tuecke's article from the Enterprise Distributed Computing
    issue of ACM Queue, Vol. 3, No. 6 - July/August 2005</ulink>).
    </para>
  </sect1>

  <sect1>
  <title>What is Globus?</title>

    <para>
    <emphasis>The <ulink url="http://www.globus.org/">Globus Toolkit</ulink>, a
    de facto standard in grid computing, is open source software that implements
    a collection of high level services at the grid infrastructure layer.
    </emphasis> These services include, among others, resource monitoring and
    discovery services (MDS), resource allocation and management (GRAM), a
    security infrastructure (GSI), and file transfer services (RFT). These
    services and libraries allow secure and transparent access to computing and
    data resources across multiple administrative domains. The Globus Toolkit
    meets most of the abstract requirements set forth in Open Grid Services
    Architecture
    (<ulink url="http://forge.gridforum.org/projects/ogsa-wg/">OGSA</ulink>).
    OGSA, under development by the Global Grid Forum
    (<ulink url="http://www.gridforum.org/">GGF</ulink>), aims to define a
    common, standard, and open architecture for the grid. The Web Services
    Resource Framework (<ulink url="http://www.globus.org/wsrf/">WSRF</ulink>),
    developed by <ulink url="http://www.oasis-open.org/">OASIS</ulink>, defines
    a family of specifications based on standard Web Services to access the
    stateful resources that OGSA needs. In fact, the Globus Toolkit is
    implemented on top of the WSRF standard. Several
    <ulink url="http://www.globus.org/grid_software/computation/">open-source
    software components</ulink> are available to deploy Globus-based grid
    solutions that address the requirements of the new grid projects.
    </para>
  </sect1>

  <sect1>
  <title>What is GridWay?</title>

    <para>
    <emphasis>GridWay is higher-level grid middleware, which uses Globus as the
    core grid middleware. So, GridWay can be used in any grid infrastructure
    based on Globus.</emphasis> The <ulink url="http://www.gridway.org/">
    GridWay</ulink> workload manager performs job execution management and
    resource brokering on a grid consisting of distinct computing platforms
    managed by Globus services. GridWay allows unattended, reliable, and efficient
    execution of single, array, or complex jobs on heterogeneous and dynamic
    grids. GridWay performs all the job scheduling and submission steps
    transparently to the end user and adapts job execution to changing grid
    conditions by providing fault recovery mechanisms, dynamic scheduling,
    migration on-request and opportunistic migration. GridWay on Globus provides
    decoupling between applications and the underlying local management systems.
    </para>
  </sect1>

  <sect1>
  <title>Grid Scheduling Infrastructure Taxonomy</title>

    <para>
    The following taxonomy, according to the level of cross-organizational
    distribution, is the most popular in today's Grid computing environments.
    </para>

    <para>
    <itemizedlist>
      <listitem>
      <para>
      <emphasis>Departmental grids</emphasis> are similar in functionality to
      compute clusters. They are owned by one user group and managed by one of
      the DRM systems described above with the aim of greater utilization of
      underlying resources. It is clear that we do not need the Globus toolkit
      for the deployment of this kind of infrastructures.
      </para>
      </listitem>

      <listitem>
      <para>
      <emphasis>Enterprise grids</emphasis> comprise several departmental grids.
      They are managed by the organization to enable diverse resource sharing
      and improve internal collaboration and achieve a better return from their
      information technology investment. Peak computing demand could be
      satisfied within the enterprise by integrating clusters and departmental
      grids. In this case, we may need the Globus toolkit to provide a common
      layer to integrate these non-interoperable computational platforms and
      the GridWay meta-scheduler to provide job management and resource
      brokering support.
      </para>
      </listitem>

      <listitem>
      <para>
      <emphasis>Partner grids</emphasis> of several scales will be mainly
      deployed within the context of different research projects, whose final
      goal is to provide large-scale, secure and reliable sharing of resources
      among partner organizations and supply-chain participants. Such partner
      grids allow access to a higher computing performance to satisfy peak
      demands and also provide support to face collaborative projects. These
      infrastructures require the Globus toolkit and the GridWay meta-scheduler
      to build computational infrastructures where resources are scattered
      across several administrative domains, each with its own security policy
      and DRM system.
      </para>
      </listitem>
    </itemizedlist>
    </para>
  </sect1>
</chapter>

<chapter>
  <title>Installation Guide</title>

  <sect1>
  <title>GridWay Architecture</title>

    <para>
    In GridWay 4.0.2, we introduced an architecture for the execution manager
    module based on a MAD (Middleware Access Driver) to interface Grid execution
    services. In this release we have taken advantage of this architecture to
    implement an information manager module with a MAD that interfaces Grid
    information services, and a transfer manager module with a MAD that
    interfaces Grid data services. Moreover, we have decoupled the scheduling
    process from the dispatch manager through the use of a external and
    selectable scheduler module.
    </para>

    <figure>
      <title>Components of the GridWay Meta-scheduler.</title>
      <graphic align="center" fileref="../images/gw_arch.jpg">
    </figure>

    <para>
    GridWay 5 architecture consists of the following components:
    </para>

    <para>
    <itemizedlist>
      <listitem>
      <para>
      <emphasis>User Interface</emphasis> provides the end user with DRM-like
      commands to submit, kill, migrate, monitor and synchronize jobs and
      includes DRMAA (Distributed Resource Management Application API) GGF
      (Global Grid Forum) standard support to develop distributed applications
      (C and JAVA bindings).
      </para>
      </listitem>

      <listitem>
      <para>
      <emphasis>GridWay core</emphasis> is responsible for job execution
      management and resource brokering providing advanced scheduling and job
      failure & recovery capabilities. The Dispatch Manager performs all
      submission stages and watches over the efficient execution of the job. The
      Information Manager, through its MADs (Middleware Access Driver), is
      responsible for host discovery and monitoring. The Execution Manager,
      through its MADs, is responsible job execution and management. The
      Transfer Manager, through its MADs, is responsible for file staging,
      remote working directory set-up and remote host clean-up.
      </para>
      </listitem>

      <listitem>
      <para>
      <emphasis>Scheduler</emphasis> takes scheduling decisions of jobs on
      available resources.
      </para>
      </listitem>

      <listitem>
      <para>
      <emphasis>Information Manager MAD</emphasis> interfaces to the monitoring
      and discovering services available in the Grid infrastructure.
      </para>
      </listitem>

      <listitem>
      <para>
      <emphasis>Execution Manager MAD</emphasis> interfaces to the Job
      Management Services available in the Grid resources.
      </para>
      </listitem>

      <listitem>
      <para>
      <emphasis>Transfer Manager MAD</emphasis> interfaces to the Data
      Management Services available in the Grid resources.
      </para>
      </listitem>
    </itemizedlist>
    </para>
  </sect1>

  <sect1>
  <title>Meta-scheduling Infrastructures with GridWay</title>

    <sect2>
    <title>Partner Grid Infrastructures</title>

      <para>
      Partner grid infrastructures of several scales are being deployed within
      the context of different research projects, whose final goal is to provide
      large-scale, secure and reliable sharing of resources among partner
      organizations and supply-chain participants. Such partner grids allow
      access to a higher computing performance to satisfy peak demands and also
      provide support to face collaborative projects. The multiple
      administration domains existing in a partner grid infrastructure prevent
      the deployment of centralized meta-schedulers, with total control over
      client requests and resource status.
      </para>

      <sect3>
      <title>User-level Meta-scheduling Infrastructures</title>

        <para>
        Most of current meta-schedulers are user-level tools that provide
        scheduling and job management functionality. This means that there is
        one scheduling instance for each user, and all scheduling instances
        compete with each other for the available resources. In this scenario,
        GridWay is installed in single-user mode by each end-user on his client
        host.
        </para>
      </sect3>

      <sect3>
      <title>Organization-level Meta- scheduling Infrastructures</title>

        <para>
        User-level meta-scheduling deployment may exhibit technical and
        socio-political difficulties within an organization, namely: the end
        users are responsible for the installation and administration of the
        meta-scheduler, a Globus client installation is required in each
        end-user system and firewall configuration must allow traffic between
        grid resources and end user systems. Undoubtedly, an approach that
        gives administrators full control of meta-scheduling deployment could
        help overcome these difficulties. Organization-level meta-schedulers
        provide support for multiple intra-organization users in each scheduling
        instance. This means that there is one scheduling instance for each
        organization, and all scheduling instances compete with each other for
        the available resources.
        </para>

        <para>
        In this scenario, GridWay is configured in multiple-user mode. This way
        the installation and configuration of GridWay will be performed by each
        system manager and the users could submit, control and monitor their
        jobs from a front-end or from submission hosts (that do not require
        GridWay and Globus installation).
        </para>

        <figure>
          <title>Site-level Meta-scheduling Infrastructure.</title>
          <graphic align="center" fileref="../images/gw_partner.jpg">
        </figure>
      </sect3>

    </sect2>

    <sect2>
    <title>Enterprise Grid Infrastructures</title>

      <para>
      Enterprise grids enable diverse resource sharing to improve internal
      collaboration and achieve a better return from information technology
      investment. Available resources within a company are better exploited
      and the administrative overhead is minimized by using Grid technology.
      The resources are part of the same administrative domain. Theses
      infrastructures require a centralized approach for scheduling and
      accounting. The administrator must be able to apply centralized usage
      policies and access to global reporting and accounting. Enterprise grid
      infrastructures require meta-schedulers to provide support for multiple
      users in a single scheduling instance.
      </para>

      <para>
      In this scenario, GridWay is installed in multiple-user mode. This way
      the installation and configuration of GridWay will be performed by the
      system manager and the users could submit, control and monitor their
      jobs from a front-end or from submission hosts (that do not require
      GridWay and Globus installation).
      </para>

      <figure>
        <title>Enterprise Grid deployment with multiple-user mode GridWay.</title>
        <graphic align="center" fileref="../images/gw_enterprise.jpg">
      </figure>
    </sect2>
  </sect1>

  <sect1>
  <title>Verifying Globus Installation</title>

    <para>
    As GridWay relies on Globus services, it is assumed that a Globus grid
    infrastructure has been installed and configured. You can perform the
    following tests to verify your Globus pre-WS installation, and to
    ensure that it will work with GridWay:

      <orderedlist>
        <listitem>
        <para>
        Authorization test:
        <screen>$ globusrun -a -r localhost</screen>
        You should receive the message "GRAM Authentication test successful".
        </para>
        </listitem>

        <listitem>
        <para>
        Submission test:
        <screen>$ globus-job-run localhost /bin/uname -a</screen>
        You should see the output of the "/bin/uname -a" command.
        </para>
        </listitem>

        <listitem>
        <para>
        File transfer test:
        <screen>
$ globus-url-copy file:///etc/hosts gsiftp://localhost/tmp/hosts1</screen>
        <screen>
$ globus-url-copy gsiftp://localhost/tmp/hosts1 file:///tmp/hosts2</screen>
        The contents of files /etc/hosts, /tmp/hosts1 and /tmp/hosts2 should be identical.
        </para>
        </listitem>

        <listitem>
        <para>
        Information retrieval test:
        <screen>
$ grid-info-search -x</screen>
        You should see a lot of information in LDIF format.
        </para>
        </listitem>
      </orderedlist>
    Change localhost to the name of the host your want to test.
    </para>

    <para>
    You can perform the following tests to verify your Globus WS installation,
    and to ensure that it will work with GridWay:
      <orderedlist>
        <listitem>
        <para>
        Submission test:
        <screen>$ globusrun-ws -submit -F localhost -s -c /bin/uname -a</screen>
        You should see the output of the "/bin/uname -a" command (along with
        other information about submission progress).
        </para>
        </listitem>

        <listitem>
        <para>
        File transfer test:
        <screen>
$ globus-url-copy file:///etc/hosts gsiftp://localhost/tmp/hosts1</screen>
        <screen>
$ globus-url-copy gsiftp://localhost/tmp/hosts1 file:///tmp/hosts2</screen>
         The contents of files /etc/hosts, /tmp/hosts1 and /tmp/hosts2 should be identical.
        </para>
        </listitem>

        <listitem>
        <para>
        Information retrieval test:
        <screen>
$ wsrf-query -x -s https://localhost:8443/wsrf/services/DefaultIndexService</screen>
        You should see a lot of information in XML format.
        </para>
        </listitem>
      </orderedlist>
      Change localhost to the name of the host your want to test.
    </para>
  </sect1>

  <sect1>
  <title>Required Software</title>

  <para>
  GridWay is distributed as a source package, required software to compile it:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    C compiler: Tested versions gcc 3.4.2, 3.4.4, 4.0.3, 4.0.3 and 4.1.2
    </para>
    </listitem>

    <listitem>
    <para>
    Globus C libraries: globus_gram_client, globus_ftp_client and globus_gass_copy
    </para>
    </listitem>

    <listitem>
    <para>
    Globus JAVA development libraries
    </para>
    </listitem>

    <listitem>
    <para>
    J2SE versions 1.4.2_10+ (Builds higher than 10) or 1.5.0+
    </para>
    </listitem>

    <listitem>
    <para>
    GNU Make
    </para>
    </listitem>

    <listitem>
    <para>
		Sudo command (only required for multiple-user mode)
    </para>
    </listitem>

    <listitem>
    <para>
    Berkeley Database library version 4.4.20 (only required to compile the accounting module)
    </para>
    </listitem>
  </itemizedlist>
  </para>
  </sect1>

  <sect1>
  <title>Platform Notes</title>

    <sect2>
    <title>Compilation Notes</title>
    <para>Not known issues</para>

    <title>Fedora Core</title>

      <para>
!     There are issues with Fedora Core 4 and Sun's Java 1.4.2. Please upgrade to Java 1.5+ on these platforms.
      </para>

    </sect2>
  </sect1>

  <sect1>
  <title>Single-User Mode Installation</title>

  <para>
  In this scenario, GridWay is installed by each end-user in his client host.
  </para>

  <para>
  Login as your user account and follow these steps:
    <orderedlist>
		  <listitem>
      <para>
		  Download the distribution file to the installation directory, for example
      your <filename>$HOME</filename> directory
      </para>
      </listitem>

      <listitem>
      <para>
      Unpack the distribution file and change to <filename>gw5</filename>
      directory:
      <screen>$ tar xzf gw5.tgz</screen>
      <screen>$ cd gw5</screen>
      </para>
      </listitem>

      <listitem>
      <para>
      Set up Globus development environment:
      <screen>$ source $GLOBUS_LOCATION/etc/globus-devel-env.sh</screen>
      or
      <screen>$ . $GLOBUS_LOCATION/etc/globus-devel-env.csh</screen>
      depending on the shell you are using.
      </para>
      </listitem>

      <listitem>
      <para>
      Run configure to set up GridWay installation. Posible options
      for configure are:
      <table frame='all'>
		<title>Configure Options.</title>
    	<tgroup cols='2' align='left' colsep='1' rowsep='1'>
    	<colspec colname='c1' colwidth='6cm'>
    	<colspec colname='c2'>
			<tbody>
		  		<row>
					<entry namest="c1">Option</entry>
					<entry namest="c2">Description</entry>
				</row>
        		<row>
        		   <entry>--prefix</entry>
        		   <entry>Sets final GridWay installation dir. Defaults to /usr/local/gw.</entry>
        		</row>
            <row>
               <entry>--with-flavor=flavor</entry>
               <entry>The configure script will try to detect the flavor (eg. gcc32dbg) of the Globus toolkit installed in your system. However,
               if the configure script is not able to detect it, specify it with this option.</entry>
            </row>
        		<row>
        		   <entry>--disable-drmaa</entry>
        		   <entry>Don't build drmaa support. Default is enabled.</entry>
        		</row>
        		<row>
        		   <entry>--disable-prews</entry>
        		   <entry>Don't build pre-web-services support. Default is enabled.
        		</row>
         		<row>
        		   <entry>--disable-ws</entry>
        		   <entry>Don't build web-services support. Default is enabled.</entry>
        		</row>
         		<row>
        		   <entry>--with-db=path_to_db</entry>
        		   <entry>Specify the Berkeley Database path to build accounting support.</entry>
        		</row>
         		<row>
        		   <entry>--with-doc</entry>
        		   <entry>Install GridWay documentation</entry>
        		</row>
          		<row>
        		   <entry>--with-examples</entry>
        		   <entry>Install examples</entry>
        		</row>
         		<row>
        		   <entry>--with-tests</entry>
        		   <entry>Install tests</entry>
        		</row>
           </tbody>
		</tgroup>
	   </table>
	   </para>
	   <para>
	   The next line will configure GridWay to include documentation and accounting
	   <screen>$ ./configure --with-doc --with-db=/usr/local/db</screen>
      </para>
      </listitem>


      <listitem>
      <para>
      Run make:
      <screen>$ make</screen>
      </para>
      </listitem>

      <listitem>
      <para>
      Run make install:
      <screen>$ make install</screen>
      </para>
      </listitem>

      <listitem>
      <para>
      Once installed, you should have the following directory tree in your
      GridWay location directory:
      <screen>
$GW_LOCATION/
    |
    +--- bin/       executables
    |
    +--- doc/       documentation [Optional]
    |
    +--- etc/       gwd.conf and job_template.default configuration files
    |
    +--- examples/  usage examples [Optional]
    |
    +--- include/   header files
    |
    +--- lib/       compiled libraries
    |
    +--- scripts/   wrapper and monitor scripts
    |
    +--- test/      test suite [Optional]
    |
    +--- var/       lock, port and log files
</screen>
      </para>
      </listitem>
    </orderedlist>
  </para>
  </sect1>

  <sect1>
  <title>Multiple-User Mode Installation</title>

  <para>
  In this scenario, the installation of GridWay is performed by the system
  manager and the users are able to submit, control and monitor their jobs
  from a front-end (GridWay server host) or from client hosts, which may not
  require a GridWay/Globus installation.  This means that there is one GridWay
  installation for each organization that provides support for multiple
  intra-organization users.
  </para>

  <para>
  Note that GridWay daemon SHOULD NOT be run as root. Only part of the
  installation will require privileged access.
  </para>

  <para>
  Login as root account and follow the next steps:
    <orderedlist>

    <listitem>
    <para>
		All of the GridWay users must be members of the same UNIX group,
    <filename>&lt;gwgroup></filename>. We recommend to create a new
    group (call <filename>gwusers</filename>, for example), and assure that
    all GridWay user accounts are members of this new group.
    </para>
    </listitem>

	  <listitem>
    <para>
    The GridWay administrator account, <filename>&lt;adminuser></filename>,
    can be an existing administrative login or a new login. We recommend
    creating a new account for the GridWay administration user
    (call <filename>gwadmin</filename>, for example). This account will own
    all of the files in the GridWay installation, all of the daemons in the
    GridWay execution and it can be used to configure GridWay once it is
    installed. Primary group of <filename>&lt;adminuser></filename>
    should be <filename>&lt;gwgroup></filename>.
    </para>
    <para>
    DO NOT use root account for the  GridWay administrator account.
    </para>
    </listitem>

    <listitem>
    <para>
		Download the distribution file to the installation directory,
    for example your <filename>/usr/local</filename> directory
    </para>
    </listitem>

    <listitem>
    <para>
    Unpack the distribution file and change ownership:
    <screen># tar xzf gw5.tgz</screen>
    <screen>
# chown -R &lt;adminuser>:&lt;gwgroup> &lt;gwlocation>
# chmod 755 &lt;gwlocation></screen>
    </para>
    <para>
    Become GridWay administrator user, and change to <filename>gw5</filename>
    directory:
    <screen># su gwadmin</screen>
    <screen>$ cd gw5</screen>
    </para>
    </listitem>

    <listitem>
    <para>
    Set up Globus development environment:
    <screen>$ source $GLOBUS_LOCATION/etc/globus-devel-env.sh</screen>
    </para>
    <para>or
    <screen>$ . $GLOBUS_LOCATION/etc/globus-devel-env.csh</screen>
    <para>
    depending on the shell you are using.
    </para>
    </listitem>

    <listitem>
    <para>
    Run configure to set up GridWay installation. Check above for possible options or
    just type <command>configure --help</command>.
	  </para>
    </listitem>


      <listitem>
      <para>
      Run make:
      <screen>$ make</screen>
      </para>
      </listitem>

      <listitem>
      <para>
      Run make install:
      <screen>$ make install</screen>
      </para>
      </listitem>

		<listitem>
    <para>
    Once installed, you should have the following directory tree in your GridWay location directory:
    <screen>
$GW_LOCATION/
    |
    +--- bin/       executables
    |
    +--- doc/       documentation [Optional]
    |
    +--- etc/       gwd.conf and job_template.default configuration files
    |
    +--- examples/  usage examples [Optional]
    |
    +--- include/   header files
    |
    +--- lib/       compiled libraries
    |
    +--- scripts/   wrapper and monitor scripts
    |
    +--- test/      test suite [Optional]
    |
    +--- var/       lock, port and log files</screen>
    </para>
    </listitem>

    <listitem>
    <para>
    The <filename>sudoers</filename> file of the <command>sudo</command> command
    should include the following
<screen>
...
# User alias specification
...
Runas_Alias     GW_USERS = %&lt;gwgroup>
...
# GridWay entries
gwadmin ALL=(GW_USERS)     NOPASSWD: /home/gwadmin/gw/bin/gw_em_mad_prews *
gwadmin ALL=(GW_USERS)     NOPASSWD: /home/gwadmin/gw/bin/gw_em_mad_ws *
gwadmin ALL=(GW_USERS)     NOPASSWD: /home/gwadmin/gw/bin/gw_tm_mad_ftp *
</screen>
    </para>

    <para>
    Usually <command>sudo</command> clears all environment variables for
    security reasons. However MADs need the <command>GW_LOCATION</command>
    and <command>GLOBUS_LOCATION</command> variables to be set. To preserve
    those variables in the MAD environment, add the following line to your
    <filename>sudoers</filename> file:
    <screen>Defaults>GW_USERS env_keep="GW_LOCATION GLOBUS_LOCATION"</screen>
    </para>
    <para>
    Please refer to the <command>sudo</command> manual page for more
    information.
    </para>

    <para>
    To test the <command>sudo</command> command configuration try to execute a
    MAD as a user in the <filename>&lt;gwgroup></filename> group, for example:
    <screen>
$ sudo -u &lt;gw_user> /home/gwadmin/gw/bin/gw_em_mad_prews
    </screen>
    </para>
    </listitem>
    </orderedlist>
  </para>

  <para>
  Following previous steps, the end-users must login to the GridWay server host
  to be able to execute GridWay commands and use the DRMAA libraries.
  </para>

  <para>
  Additionally, client hosts, that are not required to have GridWay/Globus
  installed, could be deployed to remotely interface to the GridWay server host.
  In such a case, user accounts and home directories must be shared between
  the GridWay server and the client hosts, via for example NIS and NFS; and
  <filename>&lt;gwlocation> </filename> directory should be readable on all
  client hosts. The  <filename>&lt;gwlocation> </filename> directory may be
  available via for example NFS by exporting
  <filename>&lt;gwlocation></filename> from GridWay server,
  creating <filename>&lt;gwlocation></filename>  directory in the client
  hosts, changing its ownership to
  <filename>&lt;adminuser>:&lt;gwgroup></filename>  and mounting the
  <filename>&lt;gwlocation></filename>  directory exported by the GridWay server
  on the <filename>&lt;gwlocation></filename> of the client hosts.
  </para>

  <para>
  Following those steps, a user logged in a client hosts is able to interface
  to the GridWay daemon in the GridWay server host. However, the
  <command>grid-proxy-init</command> globus command must be executed in the
  server host in order to create a proxy by, for example, executing
  <filename>  ssh &lt;GridWay server> grid-proxy-init </filename> .
  </para>

  <figure>
    <title>Site-level Meta-scheduling with Client Hosts.</title>
    <graphic align="center" fileref="../images/client-server.jpg">
  </figure>

  </sect1>

  <sect1 id='VerifGWInst'>
  <title>Verifying GridWay Installation</title>

  <para>
  In order to test the GridWay installation, login as your user account, in
  the single-mode installation, or as the <filename>&lt;gwadmin></filename>
  account, in the multiple-user installation, and follow the steps listed below:
  </para>

  <para>
  <orderedlist>
    <listitem>
    <para>
    Set up the environment variables <envar>GW_LOCATION</envar> and
    <envar>PATH</envar>:
    <screen>
$ export GW_LOCATION=&lt;path_to_GridWay_installation>
$ export PATH=$PATH:$GW_LOCATION/bin</screen>
    </para>
    <para>
    or <screen>
$ setenv GW_LOCATION &lt;path_to_GridWay_installation>
$ setenv PATH $PATH:$GW_LOCATION/bin</screen>
    </para>
    <para>
    depending on the shell you are using.
    </para>
    </listitem>

    <listitem>
    <para>
    Generate a valid proxy
    <screen>
$ grid-proxy-init
Your identity: /O=Grid/OU=GRIDWAY/CN=GRIDWAY User
Enter GRID pass phrase for this identity:
Creating proxy ................................. Done
Your proxy is valid until: Mon Oct 29 03:29:17 2005</screen>
    </para>
    </listitem>

    <listitem>
    <para>
    Show the GridWay license:
    <screen>
$ gwd -v
Copyright 2002-2006 GridWay Team, Distributed Systems Architecture
Group, Universidad Complutense de Madrid

GridWay 5 is distributed and licensed for use under the terms of the
Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0).</screen>
    </para>
    </listitem>

    <listitem>
    <para>
    Start the GridWay daemon (GWD) (in multiple-mode add the
    <command>-m</command> option):
    <screen>$ gwd</screen>
    </para>
    </listitem>

    <listitem>
    <para>
    Check the connection to GWD:
    <screen width='80'>
$ gwps
JID AID TID DM   EM   RWS START   END     EXEC   XFER   EXIT TEMPLATE       HOST
$ gwhost
HID HOSTNAME      OS        ARCH   MHZ %CPU  MEM(F/T)     DISK(F/T)  N(U/T) LRMS</screen>
    </para>
    </listitem>

    <listitem>
    <para>
    Stop GWD:
    <screen>$ pkill gwd</screen>
    </para>
    </listitem>
  </orderedlist>
  </para>

  <para>
  To perform more sophisticated tests, check the
  <emphasis>User Guide</emphasis>. If you experience problems,
  check <xref linkend='Troubleshooting'>.
  </para>
  </sect1>
</chapter>

<chapter>
<title>Core Administration Guide</title>

  <sect1>
  <title>Overview</title>

  <para>
  The configuration files for GridWay are read from the following locations:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    <filename>$GW_LOCATION/etc/gwd.conf</filename>: Configuration options
    for the GridWay daemon (GWD).
    </para>
    </listitem>

    <listitem>
    <para>
    <filename>$GW_LOCATION/etc/job_template.default</filename>: Default values
    for job's templates (i.e. job definition files).
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
  Options are defined one per line, with the following format:
  <screen>&lt;option> = [value]</screen>
  </para>

  <para>
  If the value is missing the option will fall back to its default. Blank
  lines and any character after a '#'  are ignored. Note: Job template options
  can use job or host variables to define their value, these variables are
  substituted at run time with its corresponding value
  (see the <emphasis>User Guide</emphasis>).
  </para>
  </sect1>

  <sect1 id='GWDconf'>
  <title>GridWay Daemon (GWD) Configuration</title>

  <para>
  The GridWay daemon (GWD) configuration options are defined in
  <filename>$GW_LOCATION/etc/gwd.conf</filename>. The table below summarizes
  the configuration file options, their description and default values.
  Note that blank lines and any character after a '#' are ignored.
  </para>

  <table frame='all'>
  <title>GWD Configuration File Options.</title>
    <tgroup cols='3' align='left' colsep='1' rowsep='1'>
      <colspec colname='c1'>
      <colspec colname='c2'>
      <colspec colname='c3' colwidth='2cm'>
        <tbody>
         <row>
         <entry namest="c1" nameend="c3">Connection Options</entry>
         </row>

          <row>
          <entry>GWD_PORT</entry>
          <entry>TCP/IP Port where GWD will listen for client requests. If this
          port is in use, GWD will try to bind to the next port until it finds a
          free one. The TCP/IP port used by GWD can be found in
          <filename>$GW_LOCATION/var/gwd.port</filename>
          </entry>
          <entry>6725</entry>
          </row>

          <row>
          <entry>MAX_NUMBER_OF_CLIENTS</entry>
          <entry>Maximum number of simultaneous client connections. Note that
          only blocking client requests keeps its connection open.</entry>
          <entry>20</entry>
          </row>

         <row>
         <entry namest="c1" nameend="c3">Pool Options</entry>
         </row>

          <row>
          <entry>NUMBER_OF_JOBS</entry>
          <entry>The maximum number of jobs that will be handled by the
          GridWay system</entry>
          <entry>200</entry>
          </row>

          <row>
          <entry>NUMBER_OF_ARRAYS</entry>
          <entry>The maximum number of array-jobs that will be handled by the
          GridWay system</entry>
          <entry>20</entry>
          </row>

          <row>
          <entry>NUMBER_OF_HOSTS</entry>
          <entry>The maximum number of hosts that will be handled by the
          GridWay system</entry>
          <entry>100</entry>
          </row>

          <row>
          <entry>NUMBER_OF_USERS</entry>
          <entry>The maximum number of different users in the GridWay
          system</entry>
          <entry>30</entry>
          </row>

         <row>
         <entry namest="c1" nameend="c3">Intervals</entry>
         </row>

          <row>
          <entry>SCHEDULING_INTERVAL</entry>
          <entry>Period (seconds) between two scheduling actions</entry>
          <entry>30</entry>
          </row>

          <row>
          <entry>DISCOVERY_INTERVAL</entry>
          <entry>How often (seconds) the information manager searches the Grid for
          new hosts</entry>
          <entry>300</entry>
          </row>

          <row>
          <entry>MONITORING_INTERVAL</entry>
          <entry>How often (seconds) the information manager updates the
          information of each host</entry>
          <entry>120</entry>
          </row>

          <row>
          <entry>POLL_INTERVAL</entry>
          <entry>How often (seconds) the underlying grid middleware is queried
          about the state of a job.</entry>
          <entry>60</entry>
          </row>

         <row>
         <entry namest="c1" nameend="c3">Middleware Access Driver (MAD) Options</entry>
         </row>

          <row>
          <entry>IM_MAD</entry>
          <entry>Information Manager MADs, see <xref linkend='InfDrivConf'></entry>
          <entry>-</entry>
          </row>

          <row>
          <entry>TM_MAD</entry>
          <entry>Transfer Manager MADs, see <xref linkend='TransfDrivConf'></entry>
          <entry>-</entry>
          </row>

          <row>
          <entry>EM_MAD</entry>
          <entry>Execution Manager MADs, see <xref linkend='ExecDrivConf'></entry>
          <entry>-</entry>
          </row>

         <row>
         <entry namest="c1" nameend="c3">Scheduler Options</entry>
         </row>

          <row>
          <entry>DM_SCHED</entry>
          <entry>Scheduling module, see <xref linkend='SchedDrivConf'></entry>
          <entry>-</entry>
          </row>
        </tbody>
    </tgroup>
  </table>

  <para>
  Here is an example of a GWD configuration file:
  </para>

  <screen>
#--------------------------------
# Example: GWD Configuration File
#--------------------------------
GWD_PORT              = 6725
MAX_NUMBER_OF_CLIENTS = 20
NUMBER_OF_ARRAYS = 20
NUMBER_OF_JOBS   = 200
NUMBER_OF_HOSTS  = 100
NUMBER_OF_USERS  = 30
JOBS_PER_SCHED = 10
JOBS_PER_HOST  = 10
JOBS_PER_USER  = 30
SCHEDULING_INTERVAL = 30
DISCOVERY_INTERVAL  = 300
MONITORING_INTERVAL = 120
POLL_INTERVAL       = 60
IM_MAD = mds4:gw_im_mad_mds4:-s hydrus.dacya.ucm.es::gridftp:ws
TM_MAD = gridftp:gw_tm_mad_ftp:
EM_MAD = ws:gw_em_mad_ws:rsl2
DM_SCHED = flood:gw_flood_scheduler:-h 10 -u 30 -c 5</screen>
  </sect1>

  <sect1>
  <title>Job Template Default Values</title>

  <para>
  Default values for <emphasis>every</emphasis> job template option can be set
  in <filename>$GW_LOCATION/etc/job_template.default</filename>. You can use
  this file to set the value of advance job configuration options and use them
  for all your jobs. Note, that the values set in a  job template file
  overrides those defined in job_template.default. See the
  <emphasis>User Guide</emphasis> for a detailed description of each job option.
  </para>
  </sect1>

  <sect1>
  <title>Running GWD in Single-User Mode</title>

  <para>
  In single-user mode, the GridWay daemon (GWD) should generally be run as a
  regular user. You will need to generate a valid proxy for this user before
  running GWD (please refer to Globus Toolkit documentation for more information
  about Grid certificates).
  </para>

  <para>
  Run GWD with:
  <screen>$ gwd</screen>
  </para>

  <para>
  The following additional steps may be required when running GWD in single-user mode:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    Set up <envar>GW_LOCATION</envar> variable and add
    <filename>$GW_LOCATION/bin/</filename> to your path, see
    <xref linkend='VerifGWInst'>.
    </para>
    </listitem>

    <listitem>
    <para>
    Generate a valid proxy with <command>grid-proxy-init</command>.
    </para>
    </listitem>

    <listitem>
    <para>
    Tune the values of <filename>$GW_LOCATION/etc/gwd.conf</filename> and
    <filename>$GW_LOCATION/etc/job_template.default</filename>.
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
  The GridWay daemon (GWD) handles SIGTERM and SIGINT Unix process signals, so
  to stop GWD, just find out its PID and kill it, or just:
  <screen>$ pkill gwd</screen>
  </para>

  <para>
  In order to check out if GWD is really stopped, check the log file
  <filename>$GW_LOCATION/var/gwd.log</filename>.
  </para>
  </sect1>

  <sect1>
  <title>Running GWD in Multiple-User Mode</title>

  <para>
  In multiple-user mode, the GridWay daemon (GWD) should generally be run as
  the <filename>&lt;gwadmin></filename> user. Please note that default behavior
  is to run in single-user mode.
  </para>

  <para>
  Run GWD with:
  <screen>$ gwd -m</screen>
  </para>

  <para>
  The following additional steps may be required when running GWD in
  multiple-user mode:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    Set up <envar>GW_LOCATION</envar> variable and add
    <filename>$GW_LOCATION/bin/</filename> to your path, see
    <xref linkend='VerifGWInst'>.
    </para>
    </listitem>

    <listitem>
    <para>
    Tune the values of <filename>$GW_LOCATION/etc/gwd.conf</filename> and
    <filename>$GW_LOCATION/etc/job_template.default</filename>.
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
  The GridWay daemon (GWD) handles SIGTERM and SIGINT Unix process signals, so
  to stop GWD, just find out its PID and kill it, or just:
  <screen>$ pkill gwd</screen>
  </para>

  <para>
  In order to check out if GWD is really stopped, check the log file
  <filename>$GW_LOCATION/var/gwd.log</filename>.
  </para>
  </sect1>

  <sect1>
  <title>Daemon Failure Recovery</title>

  <para>
  Since GridWay 4.9, when you start the daemon, <command>gwd</command> tries
  to recover its previous state. This is, any submitted job is stored in a
  presistent pool, and in case of a gwd (or client machine) crash these jobs are
  recovered. This includes, for jobs in wrapper state, contacting with the
  remote jobmanager.
  </para>

  <para>
  Recovery actions are performed by default, if you do not want to
  recover the previous submitted jobs use the <command> -c</command> option.
  </para>

  <para>
  For example, to start gwd in multi-user mode and clear its previous state,
  use:
  </para>

  <screen>$ gwd -c -m</screen>

  </sect1>

  <sect1 id='Logging'>
  <title>Logging</title>

  <para>
  GridWay reporting and accounting facilities provide information about overall
  performance and help troubleshoot configuration problems. GWD generates the
  following logs under the <filename>$GW_LOCATION/var</filename> directory:
  </para>

  <para>
  <itemizedlist>
      <listitem>
      <para>
      <filename>$GW_LOCATION/var/gwd.log</filename>: System level log. You can
      find log information of the activity of the middleware access drivers;
      and a coarse-grain log information about jobs.
      </para>
      </listitem>

      <listitem>
      <para>
      <filename>$GW_LOCATION/var/$JOB_ID/job.log</filename>: Detailed log
      information for each job, it includes details of job resource
      usage and performance.
      </para>
      </listitem>

      <listitem>
      <para>
      <filename>$GW_LOCATION/var/acct</filename>: Accounting information. Use
      the <command>gwacct</command> command to access the data bases. Note that
      you need Berkeley DB library (version 4.4.20).
      </para>
      </listitem>

      <listitem>
      <para>
      <filename>$GW_LOCATION/var/.lock</filename>: Used to prevent from running
      more than one instance of the daemon.
      </para>
      </listitem>

      <listitem>
      <para>
      <filename>$GW_LOCATION/var/gwd.port</filename>: TCP/IP port GWD is
      listening for client connection requests.
      </para>
      </listitem>

      <listitem>
      <para>
        <filename>$GW_LOCATION/var/globus-gw.log</filename>: Used to
        encapsulate GridWay in a GRAM service (please refer to the Grid4Utility
        project web page for more information). This log file follows the
        globus fork job starter's format (based on SEG, Scheduler Event Generator
        messages):
      </para>
      <screen>001;TIMESTAMP;JOBID;STATE;EXIT_CODE</screen>
      </listitem>
  </itemizedlist>
  </para>
  </sect1>

  <sect1 id="Troubleshooting">
  <title>Troubleshooting</title>

  <para>
  If you are having problems starting GWD, check the errors listed below. Also
  try checking the daemon logs, see <xref linkend='Logging'>.
  </para>

  <formalpara>
  <title>Lock file exists</title>

    <para>
    GridWay finishes with the following message, when you try to start it:
    <screen>Error! Lock file &lt;path_to_GridWay>/var/.lock exists.</screen>
    be sure that no other GWD is running, then remove the lock file and try again.
    </para>
  </formalpara>

  <formalpara>
  <title>Error in MAD initialization</title>

    <para>
    GridWay finishes with the following message, when you try to start it:
  <screen>
Error in Execution MAD prews initialization, exiting. Check path,
you have a valid proxy...</screen>
    check that you have generated a valid proxy (for example with the
    grid-proxy-info command). Also, check that the directory
    <filename>$GW_LOCATION/bin</filename> is in your path, and the executable name
    of all the MADs defined in <filename>gwd.conf</filename>.
    </para>
  </formalpara>

  <formalpara>
  <title>Error contacting GWD</title>

    <para>
    Client commands, like <command>gwps</command>, finish with the message:
    <screen>
connect(): Connection refused
Could not connect to gwd</screen>
    be sure that GWD is running (ex. <emphasis>pgrep -l gwd</emphasis>) , if it
    is running check that you can connect to GWD (ex. <emphasis>telnet
    `cat $GW_LOCATION/var/gwd.port`</emphasis>)
    </para>
  </formalpara>
  </sect1>
</chapter>

<chapter>
<title>Middleware Access Driver (MAD) Configuration Guide</title>

  <sect1>
  <title>Configuration Overview</title>

  <para>
  GridWay uses several Middleware Access Drivers (MAD) to interface different
  Grid services. The following MADs are part of the GridWay distribution:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    Execution Managers to interface pre-WS GRAM and WS GRAM services.
    </para>
    </listitem>

    <listitem>
    <para>
    Information Managers to interface MDS2 (MDS and GLUE schemas) and MDS4 services.
    </para>
    </listitem>

    <listitem>
    <para>
    Transfer Managers to interface GridFTP servers.
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
  Additionally GridWay uses an external and selectable scheduler module,
  to schedule jobs. The following schedulers are distributed with GridWay:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    Round-robin/flood Scheduler.
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
  These drivers are configured and selected via the GWD configuration interface
  described in <xref linkend='GWDconf'>. Additionally you may need to configure
  your environment (see <xref linkend="VerifGWInst">) in order to successfully
  load the MADs into the GWD core.
  </para>
  </sect1>

  <sect1 id='ExecDrivConf'>
  <title>
  Execution Driver Configuration
  </title>

  <para>
  Execution Driver interface Grid Execution Services, being responsible for
  low-level job execution and management. GridWay distribution includes the
  following Execution MADs:
  </para>

  <para>
  <itemizedlist>

    <listitem>
    <para>
    Pre-WS GRAM (Globus Toolkit 2.4 and above)
    </para>
    </listitem>

    <listitem>
    <para>
    WS GRAM (Globus Toolkit 4.0)
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
  Note that the use of these MADs requires a valid proxy.
  </para>

  <para>
  Execution MADs are configured with the <varname>EM_MAD</varname> option in
  the <filename>$GW_LOCATION/etc/gwd.conf</filename> file, with the following
  format:
  <screen>EM_MAD = &lt;mad_name>:&lt;path_to_mad>:&lt;rsl|rsl_nsh|rsl2></screen>
  </para>

  <para>
  where:
  </para>
  <para>
    <itemizedlist>
      <listitem>
      <para>
      <command>mad_name</command>: It is a tag to further refer to this
      Execution Driver, and it is also useful for logging purposes.
      </para>
      </listitem>

      <listitem>
      <para>
      <command>path_to_mad</command>: It is the name of the Execution Driver
      executable, which <emphasis>must</emphasis> be placed in the
      <filename>$GW_LOCATION/bin</filename> directory.
      </para>
      </listitem>

      <listitem>
        <para>
        <command>rsl|rsl_nsh|rsl2</command>: Selects the language that GWD will
        use to describe job requests. It can be
        <emphasis>rsl</emphasis> (intended to be used with pre-WS drivers),
        <emphasis>rsl_nsh</emphasis> (intended to be used with pre-WS drivers over resources with non-shared home directories, like in LCG) and
        <emphasis>rsl2</emphasis> (intended to be used with WS drivers).
        </para>
      </listitem>
    </itemizedlist>
  </para>

  <para>
  For example the following line will configure GridWay to use the Execution
  Driver <command>gw_em_mad_prews</command> using RSL syntax with name
  <emphasis>prews</emphasis>:
  <screen>EM_MAD = prews:gw_em_mad_prews:rsl</screen>
  </para>

  <para>
  To use WS-GRAM services you can include the following line in your
  <filename>$GW_LOCATION/etc/gwd.conf</filename> file:
  <screen>EM_MAD = ws:gw_em_mad_ws:rsl2</screen>
  </para>

  <note>
  <para>You can simultaneously use as many Execution Drivers as you need
  (up to 10). So, GridWay allows you to simultaneously use pre-WS and WS
  Globus Services.
  </para>
  </note>
  </sect1>

  <sect1 id='TransfDrivConf'>
  <title>File Transfer Driver Configuration</title>

  <para>
  File Transfer Driver interface Grid Data Management Services, being
  responsible for file staging, remote working directory set-up and remote host
  clean up. GridWay distribution includes:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    GridFTP server (version 1.1.2 and above)
    </para>
    <para>
    Dummy Transfer driver (to be used with clusters without shared home)
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
  The use of this driver requires a valid Proxy.
  </para>

  <para>
  File Transfer Managers are configured with the TM_MAD option in the
  <filename>gwd.conf</filename> file, with the format:
  <screen>TM_MAD = &lt;mad_name>:&lt;path_to_mad>:[arg]</screen>
  </para>
  <para>
    where:
  </para>
  <para>
    <itemizedlist>
      <listitem>
        <para>
          <command>mad_name</command>: It is a tag to further refer to this
          File Transfer Driver, and it is also useful for logging purposes.
        </para>
      </listitem>

      <listitem>
        <para>
          <command>path_to_mad</command>: It is the name of the File Transfer
          Driver executable, which <emphasis>must</emphasis> be placed in the
          <filename>$GW_LOCATION/bin</filename> directory.
        </para>
      </listitem>

      <listitem>
        <para>
          <command>arg</command>:Additional argument to be passed to the
          File Transfer executable.
        </para>
      </listitem>
    </itemizedlist>
  </para>

  <para>
  To configure Transfer Driver add a line to
  <filename>$GW_LOATION/etc/gwd.conf</filename>, with the following format:
  <screen>TM_MAD = &lt;mad_name>:&lt;path_to_mad>:[arguments]></screen>
  </para>

  <sect2>
  <title>Configuring the GridFTP Transfer Driver</title>
  <para>
  The GridFTP driver does not require any command line arguments. So to
  configure the driver add the following line to
  <filename>$GW_LOCATION/etc/gwd.conf</filename>:
  <screen>TM_MAD = gridftp:gw_tm_mad_ftp:</screen>
  </para>
  <para>
  The name of the driver will be later used to specify the transfer mechanisms
  with Grid resource.
  </para>
  </sect2>

  <sect2>
  <title>Configuring the Dummy Transfer Driver</title>
  <para>
  The Dummy driver should be used with those resources (clusters) which do not
  have   a shared home. In this case transfer and execution are performed as
  follows:
  <itemizedlist>
    <listitem>
    <para>
    The Dummy Transfer MAD performs data movements from the cluster worker node
    and the client using a reverse server model.
   </para>
    </listitem>

    <listitem>
    <para>
     The <emphasis>rsl_nsh</emphasis> RSL generation function is used, which
     transfers the wrapper, along with its stdout and stderr streams.
    </para>
    </listitem>

    <listitem>
    <para>
    The wrapper executing in the worker node automatically
    transfers job.env and input/output files from the client.
    </para>
    </listitem>

  </itemizedlist>

  <para>
  The following servers can be configured to access files on the client machine:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    <emphasis>GASS Server</emphasis>, started for each user.
    </para>
    <para>
    <emphasis>GridFTP</emphasis>, specified by its url an running on the
    GridWay server.
    </para>
    </listitem>
  </itemizedlist>
  </para>

  <para>
   The Dummy driver behavior is specified with the following command line
   arguments:
  </para>
  <para>
    <itemizedlist>
      <listitem>
        <para>
          <command>-u &lt;URL></command>:URL of the GridFTP server.
        </para>
      </listitem>
      <listitem>
        <para>
          <command>-g</command>: Use a user GASS server to transfer files.
        </para>
      </listitem>
    </itemizedlist>
    </para>

  <para>Sample configuration to use a GridFTP server:
  <screen>TM_MAD = dummy:gw_tm_mad_dummy:-u gsiftp\://hostname</screen>
  </para>
  <important>
  <para>
   You MUST escape the colon character in gsiftp URL.
   Also hostname should be the host running the GridWay instance.
  </para>
  </important>

  <para>Sample configuration to use GASS servers:
  <screen>TM_MAD = dummy:gw_tm_mad_dummy:-g</screen>
  </para>

  </sect2>

  </sect1>

  <sect1 id='InfDrivConf'>
  <title>Information Driver Configuration</title>

  <para>
  Information Driver interface Grid Monitoring Services, being responsible for
  host discovery and monitoring. The following Information Drivers are included
  in GridWay:
  </para>

  <para>
  <itemizedlist>
    <listitem>
    <para>
    Static host information data
    </para>
    </listitem>

    <listitem>
    <para>
    MDS2 with MDS schema (Globus Toolkit 2.4)
    </para>
    </listitem>

    <listitem>
    <para>
    MDS2 with GLUE schema (Globus Toolkit 2.4 and LCG middleware)
    </para>
    </listitem>

    <listitem>
    <para>
    MDS4 (Globus Toolkit 4.0)
    </para>
    </listitem>

  </itemizedlist>
  </para>

  <para>
  To configure an Information Driver add a line to
  <filename>$GW_LOATION/etc/gwd.conf</filename>, with the following format:
  <screen>IM_MAD = &lt;mad_name>:&lt;path_to_mad>:[args]:[nice]:&lt;tm_mad_name>:&lt;em_mad_name></screen>
  </para>
  <para>
  where:
  </para>
  <para>
    <itemizedlist>
      <listitem>
        <para>
          <command>mad_name</command>:It is a tag to further refer to this
          Information Driver.
        </para>
      </listitem>

      <listitem>
        <para>
          <command>path_to_mad</command>: It is the name of the Information Driver
          executable. Use an absolute path or include the Information Driver
          directory in the <envar>PATH</envar> variable (such directory is
          <filename>$GW_LOCATION/bin</filename> by default).
        </para>
      </listitem>

      <listitem>
        <para>
          <command>arg</command>:Additional argument to be passed to the
          Information Driver executable.
        </para>
      </listitem>

      <listitem>
        <para>
          <command>nice</command>: Integer value, that will be added to the rank
          calculated for the hosts managed by this Information Driver. So you
          can prioritize, at a coarse level, hosts from different Information
          Drivers (or Grids).
        </para>
      </listitem>

      <listitem>
        <para>
          <command>tm_mad_name</command>: File Transfer Driver to be used with
          the hosts managed by this Information Driver.
        </para>
      </listitem>

      <listitem>
        <para>
          <command>em_mad_name</command>:Execution Driver to be used with
          the hosts managed by this Information Driver.
        </para>
      </listitem>
    </itemizedlist>
  </para>

  <para>
  For example, to configure GWD to access a MDS4 hierarchical information service:
  <screen>IM_MAD = mds4:gw_im_mad_mds4:-s hydrus.dacya.ucm.es::gridftp:ws</screen>
  </para>

  <para>
  All the Information Drivers provided with GridWay use a common interface
  to configure their operation mode. The arguments used by the Information
  Drivers are:
  </para>

  <para>
    <itemizedlist>
      <listitem>
        <para>
          <command>-s &lt;server></command>: The information server in a
          hierarchical configuration, i.e. MDS2 GIIS or MDS4 root IndexService.
        </para>
      </listitem>

      <listitem>
        <para>
          <command>-l &lt;host list></command>: A host list file to be used by
          GridWay, only relevant for static discovery and monitoring. See the
          Information Driver operation mode below (Relative path to $GW_LOCATION).
        </para>
      </listitem>

      <listitem>
        <para>
          <command>-b &lt;base></command>: The Virtual Organization name in the
          DN of the LDIF entries, i.e. the Mds-Vo-name attribute, only relevant
          for MDS2.
        </para>
      </listitem>

      <listitem>
        <para>
          <command>-f &lt;filter></command>:Additional requirements to be
          imposed to all the hosts managed by this Information Driver, in LDIF
          format.
        </para>
      </listitem>
    </itemizedlist>
  </para>


  <para>
  These options allow you to configure your Information Drivers in the
  three operation modes, described below.
  </para>

  <sect2>
  <title>Static Discovery and Monitoring (SS mode)</title>
    <para>
    In this mode, hosts are statically discovered by reading a host list file
    (note: each time it is read). Also the attributes of each host are read
    from files. Hint: Use this mode for testing purposes and not in a production
    environment. To configure a Information Driver in SS mode use the host
    list option, for example:
    <screen>IM_MAD = static:gw_im_mad_static:-l examples/im/host.static::gridftp:ws</screen>
    </para>

    <para>
    The host list file contains one host per line, with format:
    <screen>FQDN    attribute_file</screen>
    </para>
    <para>
    where:
    </para>

    <para>
    <itemizedlist>
      <listitem>
      <para>
      <command>FQDN</command>: is the Full Qualified Domain Name of the host.
      </para>
      </listitem>

      <listitem>
      <para>
      <command>attribute_file</command>: is the name of the file with the static
      attributes of this host. Relative to the <filename>GW_LOCATION</filename>
      directory.
      </para>
      </listitem>
    </itemizedlist>
    </para>

    <para>
    For example (you can find this file, <filename>host.list</filename>, in
    <filename>$GW_LOCATION/examples/im/</filename>)
    <screen>
hydrus.dacya.ucm.es examples/im/hydrus.attr
draco.dacya.ucm.es examples/im/draco.attr</screen>
    </para>

    <para>
    The <parameter>attribute_file</parameter> includes a
    <emphasis>single line</emphasis> with the host information and
    <emphasis>other lines</emphasis> with the information of each queue
    (one line per queue).  Use the examples below as templates for your hosts.
    </para>

    <para>
    Example of attribute file for a PBS cluster (you can find this file in
    <filename>$GW_LOCATION/examples/im/</filename>):
    <screen>
HOSTNAME="hydrus.dacya.ucm.es" ARCH="i686" OS_NAME="Linux" OS_VERSION="2.6.4"
CPU_MODEL="Intel(R) Pentium(R) 4 CPU 2" CPU_MHZ=2539 CPU_FREE=098 CPU_SMP=1
NODECOUNT=4 SIZE_MEM_MB=503 FREE_MEM_MB=188 SIZE_DISK_MB=55570
FREE_DISK_MB=39193 FORK_NAME="jobmanager-fork" LRMS_NAME="jobmanager-pbs"
LRMS_TYPE="pbs" QUEUE_NAME[0]="q4small" QUEUE_NODECOUNT[0]=1
QUEUE_FREENODECOUNT[0]=4 QUEUE_MAXTIME[0]=0 QUEUE_MAXCPUTIME[0]=20
QUEUE_MAXCOUNT[0]=4 QUEUE_MAXRUNNINGJOBS[0]=0 QUEUE_MAXJOBSINQUEUE[0]=1
QUEUE_STATUS[0]="enabled" QUEUE_DISPATCHTYPE[0]="batch"
QUEUE_NAME[1]="q4medium" QUEUE_NODECOUNT[1]=4 QUEUE_FREENODECOUNT[1]=4
QUEUE_MAXTIME[1]=0 QUEUE_MAXCPUTIME[1]=120 QUEUE_MAXCOUNT[1]=4
QUEUE_MAXRUNNINGJOBS[1]=0 QUEUE_MAXJOBSINQUEUE[1]=1
QUEUE_STATUS[1]="enabled" QUEUE_DISPATCHTYPE[1]="batch"</screen>
    </para>

    <para>
    Example of attribute file for a Fork Desktop (you can find this file in
    <filename>$GW_LOCATION/examples/im/</filename>):
    <screen>
HOSTNAME="draco.dacya.ucm.es" ARCH="i686" OS_NAME="Linux" OS_VERSION="2.6-xen"
CPU_MODEL="Intel(R) Pentium(R) 4 CPU 3" CPU_MHZ=3201 CPU_FREE=185 CPU_SMP=2
NODECOUNT=2 SIZE_MEM_MB=431 FREE_MEM_MB=180 SIZE_DISK_MB=74312
FREE_DISK_MB=40461 FORK_NAME="jobmanager-fork" LRMS_NAME="jobmanager-fork"
LRMS_TYPE="fork" QUEUE_NAME[0]="default" QUEUE_NODECOUNT[0]=1
QUEUE_FREENODECOUNT[0]=1 QUEUE_MAXTIME[0]=0 QUEUE_MAXCPUTIME[0]=0
QUEUE_MAXCOUNT[0]=0 QUEUE_MAXRUNNINGJOBS[0]=0 QUEUE_MAXJOBSINQUEUE[0]=0
QUEUE_STATUS[0]="0" QUEUE_DISPATCHTYPE[0]="Immediate"</screen>
    </para>
    <para>
    To use the WS version of these files just change jobmanager-fork with Fork
    and jobmanager-pbs with PBS.
    </para>
  </sect2>

  <sect2>
  <title>Static Discovery and Dynamic Monitoring (SD mode)</title>

    <para>
    Hosts are discovered by reading a host list file. However, the information
    of each host is gathered by querying its information service (GRIS in MDS2
    or the DefaultIndexService in MDS4). Hint: Use this mode if the resources in
    your Grid does not vary too much, i.e. resource are not added or removed
    very often. To configure a Information Driver in SD mode use the host
    list option, for example:
    <screen>IM_MAD = glue:gw_im_mad_mds2_glue:-l examples/im/host.list::gridftp:prews</screen>
    </para>
    <para>
    In this case the host list file contains one host per line, with format:
    <screen>
FQDN
...
FQDN</screen>
    </para>

    <para>
    where:
    <itemizedlist>
      <listitem>
      <para>
      <command>FQDN</command>: is the Full Qualified Domain Name of the host.
      </para>
      </listitem>
    </itemizedlist>
    </para>

    <para>
    For example (you can find this file in
    <filename>$GW_LOCATION/examples/im/</filename>)
    <screen>
hydrus.dacya.ucm.es
ursa.dacya.ucm.es
draco.dacya.ucm.es</screen>
    </para>

    <note>
    <para>
    The information services of each host (GRIS or/and DefaultIndexServices)
    must be properly configured to use this mode.
    </para>
    </note>
  </sect2>

  <sect2>
  <title>Dynamic Discovery and Monitoring (DD mode)</title>

    <para>
    In this mode, hosts are discovered and monitored by directly accessing the
    Grid Information Service. Hint: Use this mode if the resources in your Grid
    does vary too much, i.e. resource are added or removed very often. To
    configure a Information Driver in SD mode use the server option,
    for example:
    <screen>IM_MAD = mds4:gw_im_mad_mds4:-s hydrus.dacya.ucm.es::gridftp:ws</screen>
    </para>

    <note>
    <para>
    A hierarchical information service (GIIS or/and DefaultIndexService)
    must be properly configured to use this mode.
    </para>
    </note>

    <para>
    If you are using a MDS2 information service you may need to specify the
    Virtual Organization name in the DN of the LDIF entries
    (<emphasis>Mds-vo-name</emphasis>) with the base option described above.
    </para>

    <note>
    <para>
    You can simultaneously use as many Information Drivers as you need
    (up to 10). So, GridWay allows you to simultaneously use MDS2 and MDS4
    Services. You can also use resources from different Grids at the same time.
    </para>
    </note>

    <note>
    <para>
    You can mix SS, SD and DD modes in the same Information Driver.
    </para>
    </note>
  </sect2>
  </sect1>

  <sect1 id='SchedDrivConf'>
  <title>Scheduling Driver Configuration</title>

    <para>
    The Scheduler Driver is used to schedule jobs on the available Grid
    resources. The following schedulers are included in GridWay:
    </para>

    <para>
    <itemizedlist>
      <listitem>
      <para>
      Round-Robin/Flooding: This is a simple scheduling algorithm. It maximizes
      the number of jobs submitted to the Grid. Available resources, ordered by
      rank, are flooded with user jobs in a round-robin fashion.
      (the <emphasis>User Guide</emphasis> explains how to define the rank for
      each job). The new version of this scheduler (from GridWay 5.1) also
      considers past history of Grid resources: failed executions
      are now considered when scheduling the jobs of each user.
      </para>
      </listitem>
    </itemizedlist>
    </para>

    <para>
    The schedulers are configured with the <parameter>DM_SCHED</parameter>
    option in the <filename>gwd.conf</filename> file, with the format:
    <screen>DM_SCHED = &lt;sched_name>:&lt;path_to_sched>:[args]</screen>
    </para>
    <para>
    where:
    </para>
    <para>
      <itemizedlist>
        <listitem>
          <para>
            <command>sched_name</command>:It is a tag to further refer to this
            scheduler.
          </para>
        </listitem>

        <listitem>
          <para>
            <command>path_to_mad</command>:It is the name of the  Scheduler
            executable. Use an absolute path or include the Scheduler executable
            directory in the PATH variable (such directory is
            <filename>$GW_LOCATION/bin</filename> by default).
          </para>
        </listitem>

        <listitem>
          <para>
            <command>arg</command>:Additional argument to be passed to the
            Scheduler executable.
          </para>
        </listitem>
      </itemizedlist>
    </para>

    <para>
    To configure the round-robin/flood scheduler add the following line to
    <filename>$GW_LOCATION/etc/gwd.conf</filename>:
    <screen>flood:gw_flood_scheduler:-h 10 -u 30 -c 5 -s 15</screen>
    </para>
    <para>
    where
    </para>

    <para>
      <itemizedlist>
        <listitem>
          <para>
          <command>-h</command>:   The max number of jobs that the scheduler
          submits to a given host. Default value is 10,
          0 dispatch to each host as many jobs as possible.
          </para>
        </listitem>

        <listitem>
          <para>
            <command>-u</command>: The maximum number of simultaneous RUNNING
            jobs per user. Default value is 30, 0 dispatch as many jobs as possible.
          </para>
        </listitem>

        <listitem>
          <para>
            <command>-c</command>: Scheduling Chunk. Jobs of the same user are
            submitted in a round-robin fashion with the given chunk. This allows
            the administrator to establish a basic sharing policy.
            Default value is 5
          </para>
        </listitem>
        <listitem>
          <para>
            <command>-s</command>: Dispatch Chunk. The maximum number of jobs
            that will be dispatched each scheduling action. Default value is
            15, 0 dispatch as many jobs as possible.
          </para>
        </listitem>
      </itemizedlist>
    </para>

    <note>
    <para>
    GridWay 5 includes a scheduler template to develop custom schedulers.
    The previous simple flood (user round-robin) scheduler is included as
    example.
    </para>
    </note>
  </sect1>
</chapter>
</book>

